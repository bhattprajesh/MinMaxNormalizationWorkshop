{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè° Min-Max Normalization Workshop\n",
    "## Team Name: Group-4\n",
    "## Team Members: Prajesh Bhatt, Kevinkumar Patel\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùó Why We Normalize: The Problem with Raw Feature Scales\n",
    "\n",
    "In housing data, features like `Price` and `Lot_Size` can have values in the hundreds of thousands, while others like `Num_Bedrooms` range from 1 to 5. This creates problems when we use algorithms that depend on numeric magnitudes.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è What Goes Wrong Without Normalization\n",
    "\n",
    "---\n",
    "\n",
    "### 1. üß≠ K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN uses the **Euclidean distance** formula:\n",
    "\n",
    "$$\n",
    "d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + \\cdots}\n",
    "$$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- $ \\text{Price}_1 = 650{,}000, \\quad \\text{Price}_2 = 250{,}000 $\n",
    "- $ \\text{Bedrooms}_1 = 3, \\quad \\text{Bedrooms}_2 = 2 $\n",
    "\n",
    "Now compute squared differences:\n",
    "\n",
    "$$\n",
    "(\\text{Price}_1 - \\text{Price}_2)^2 = (650{,}000 - 250{,}000)^2 = (400{,}000)^2 = 1.6 \\times 10^{11}\n",
    "$$\n",
    "$$\n",
    "(\\text{Bedrooms}_1 - \\text{Bedrooms}_2)^2 = (3 - 2)^2 = 1\n",
    "$$\n",
    "\n",
    "‚û°Ô∏è **Price dominates the distance calculation**, making smaller features like `Bedrooms` irrelevant.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. üìâ Linear Regression\n",
    "\n",
    "Linear regression estimates:\n",
    "\n",
    "$$\n",
    "y = \\beta_1 \\cdot \\text{Price} + \\beta_2 \\cdot \\text{Bedrooms} + \\beta_3 \\cdot \\text{Lot\\_Size} + \\epsilon\n",
    "$$\n",
    "\n",
    "If `Price` has very large values:\n",
    "- Gradient updates for $ \\beta_1 $ will be **much larger**\n",
    "- Gradient updates for $ \\beta_2 $ (Bedrooms) will be **very small**\n",
    "\n",
    "‚û°Ô∏è The model overfits high-magnitude features like `Price`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. üß† Neural Networks\n",
    "\n",
    "A single neuron computes:\n",
    "\n",
    "$$\n",
    "z = w_1 \\cdot \\text{Price} + w_2 \\cdot \\text{Bedrooms} + w_3 \\cdot \\text{Lot\\_Size}\n",
    "$$\n",
    "\n",
    "If:\n",
    "\n",
    "- $ \\text{Price} = 650{,}000 $\n",
    "- $ \\text{Bedrooms} = 3 $\n",
    "- $ \\text{Lot\\_Size} = 8{,}000 $\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "z \\approx w_1 \\cdot 650{,}000 + w_2 \\cdot 3 + w_3 \\cdot 8{,}000\n",
    "$$\n",
    "\n",
    "‚û°Ô∏è Even with equal weights, `Price` contributes **most of the activation**, making it difficult for the network to learn from other features.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Solution: Min-Max Normalization\n",
    "\n",
    "We apply the transformation:\n",
    "\n",
    "$$\n",
    "x_{\\text{normalized}} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "This scales all features to a common range (typically $[0, 1]$).\n",
    "\n",
    "| Feature      | Raw Value | Min     | Max     | Normalized Value |\n",
    "|--------------|-----------|---------|---------|------------------|\n",
    "| Price        | 650,000   | 250,000 | 800,000 | 0.72             |\n",
    "| Bedrooms     | 3         | 1       | 5       | 0.50             |\n",
    "| Lot_Size     | 8,000     | 3,000   | 10,000  | 0.714            |\n",
    "\n",
    "‚û°Ô∏è Now, **each feature contributes fairly** to model training or distance comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Use Case: Housing Data\n",
    "We are normalizing features from a real estate dataset to prepare it for machine learning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "House_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Area_sqft",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Num_Bedrooms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Num_Bathrooms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year_Built",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Lot_Size",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "36d29360-7bfd-4d5a-82d8-eedef055aa6b",
       "rows": [
        [
         "0",
         "H100000",
         "574507",
         "1462",
         "3",
         "3",
         "2002",
         "4878"
        ],
        [
         "1",
         "H100001",
         "479260",
         "1727",
         "2",
         "2",
         "1979",
         "4943"
        ],
        [
         "2",
         "H100002",
         "597153",
         "1403",
         "5",
         "2",
         "1952",
         "5595"
        ],
        [
         "3",
         "H100003",
         "728454",
         "1646",
         "5",
         "2",
         "1992",
         "9305"
        ],
        [
         "4",
         "H100004",
         "464876",
         "853",
         "1",
         "1",
         "1956",
         "7407"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House_ID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Area_sqft</th>\n",
       "      <th>Num_Bedrooms</th>\n",
       "      <th>Num_Bathrooms</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Lot_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H100000</td>\n",
       "      <td>574507</td>\n",
       "      <td>1462</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>4878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H100001</td>\n",
       "      <td>479260</td>\n",
       "      <td>1727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "      <td>4943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H100002</td>\n",
       "      <td>597153</td>\n",
       "      <td>1403</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1952</td>\n",
       "      <td>5595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H100003</td>\n",
       "      <td>728454</td>\n",
       "      <td>1646</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>9305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H100004</td>\n",
       "      <td>464876</td>\n",
       "      <td>853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1956</td>\n",
       "      <td>7407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  House_ID   Price  Area_sqft  Num_Bedrooms  Num_Bathrooms  Year_Built  \\\n",
       "0  H100000  574507       1462             3              3        2002   \n",
       "1  H100001  479260       1727             2              2        1979   \n",
       "2  H100002  597153       1403             5              2        1952   \n",
       "3  H100003  728454       1646             5              2        1992   \n",
       "4  H100004  464876        853             1              1        1956   \n",
       "\n",
       "   Lot_Size  \n",
       "0      4878  \n",
       "1      4943  \n",
       "2      5595  \n",
       "3      9305  \n",
       "4      7407  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üî¢ Load and display dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/housing_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Step 1 ‚Äî Implement Min-Max Normalization on the Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original vs Normalized (first 5 rows) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Price",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Area_sqft",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Num_Bedrooms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Num_Bathrooms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Lot_Size",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Price_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Area_sqft_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Num_Bedrooms_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Num_Bathrooms_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lot_Size_norm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "69cbb03d-25e7-484c-b9c2-7828e5041601",
       "rows": [
        [
         "0",
         "574507",
         "1462",
         "3",
         "3",
         "4878",
         "0.4852261304477206",
         "0.3157894736842105",
         "0.5",
         "1.0",
         "0.32081403044341494"
        ],
        [
         "1",
         "479260",
         "1727",
         "2",
         "2",
         "4943",
         "0.3878274972415634",
         "0.39458816532857566",
         "0.25",
         "0.5",
         "0.3261912640635341"
        ],
        [
         "2",
         "597153",
         "1403",
         "5",
         "2",
         "5595",
         "0.5083837044142144",
         "0.2982456140350877",
         "1.0",
         "0.5",
         "0.38012905360688287"
        ],
        [
         "3",
         "728454",
         "1646",
         "5",
         "2",
         "9305",
         "0.642650798796207",
         "0.3705025275052037",
         "1.0",
         "0.5",
         "0.6870450033090668"
        ],
        [
         "4",
         "464876",
         "853",
         "1",
         "1",
         "7407",
         "0.3731185621566015",
         "0.13470115967885815",
         "0.0",
         "0.0",
         "0.5300297816015883"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Area_sqft</th>\n",
       "      <th>Num_Bedrooms</th>\n",
       "      <th>Num_Bathrooms</th>\n",
       "      <th>Lot_Size</th>\n",
       "      <th>Price_norm</th>\n",
       "      <th>Area_sqft_norm</th>\n",
       "      <th>Num_Bedrooms_norm</th>\n",
       "      <th>Num_Bathrooms_norm</th>\n",
       "      <th>Lot_Size_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>574507</td>\n",
       "      <td>1462</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4878</td>\n",
       "      <td>0.485226</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479260</td>\n",
       "      <td>1727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4943</td>\n",
       "      <td>0.387827</td>\n",
       "      <td>0.394588</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.326191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597153</td>\n",
       "      <td>1403</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5595</td>\n",
       "      <td>0.508384</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.380129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728454</td>\n",
       "      <td>1646</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9305</td>\n",
       "      <td>0.642651</td>\n",
       "      <td>0.370503</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.687045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>464876</td>\n",
       "      <td>853</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7407</td>\n",
       "      <td>0.373119</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Area_sqft  Num_Bedrooms  Num_Bathrooms  Lot_Size  Price_norm  \\\n",
       "0  574507       1462             3              3      4878    0.485226   \n",
       "1  479260       1727             2              2      4943    0.387827   \n",
       "2  597153       1403             5              2      5595    0.508384   \n",
       "3  728454       1646             5              2      9305    0.642651   \n",
       "4  464876        853             1              1      7407    0.373119   \n",
       "\n",
       "   Area_sqft_norm  Num_Bedrooms_norm  Num_Bathrooms_norm  Lot_Size_norm  \n",
       "0        0.315789               0.50                 1.0       0.320814  \n",
       "1        0.394588               0.25                 0.5       0.326191  \n",
       "2        0.298246               1.00                 0.5       0.380129  \n",
       "3        0.370503               1.00                 0.5       0.687045  \n",
       "4        0.134701               0.00                 0.0       0.530030  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sanity Check: min and max of each normalized column ===\n",
      "     Price_norm  Area_sqft_norm  Num_Bedrooms_norm  Num_Bathrooms_norm  \\\n",
      "min         0.0             0.0                0.0                 0.0   \n",
      "max         1.0             1.0                1.0                 1.0   \n",
      "\n",
      "     Lot_Size_norm  \n",
      "min            0.0  \n",
      "max            1.0  \n"
     ]
    }
   ],
   "source": [
    "# ‚úçÔ∏è Implement Min-Max Normalization manually (no sklearn/numpy)\n",
    "# Normalize: Price, Area_sqft, Num_Bedrooms, Num_Bathrooms, Lot_Size\n",
    "\n",
    "# Define the features to normalize\n",
    "features_to_normalize = ['Price', 'Area_sqft', 'Num_Bedrooms', 'Num_Bathrooms', 'Lot_Size']\n",
    "\n",
    "# Work on a copy so we preserve the original values\n",
    "df_norm = df.copy()\n",
    "\n",
    "# Apply Min-Max formula: x_norm = (x - x_min) / (x_max - x_min)\n",
    "# Pure pandas ‚Äî no sklearn or numpy\n",
    "for col in features_to_normalize:\n",
    "    col_min = df[col].min()\n",
    "    col_max = df[col].max()\n",
    "    df_norm[col + '_norm'] = (df[col] - col_min) / (col_max - col_min)\n",
    "\n",
    "# Display original vs normalized columns side by side\n",
    "norm_cols = [c + '_norm' for c in features_to_normalize]\n",
    "print('=== Original vs Normalized (first 5 rows) ===')\n",
    "display(df_norm[features_to_normalize + norm_cols].head())\n",
    "\n",
    "# Sanity check: every normalized column should have min=0 and max=1\n",
    "print('\\n=== Sanity Check: min and max of each normalized column ===')\n",
    "print(df_norm[norm_cols].agg(['min', 'max']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Talking Points #1 ‚Äî Min-Max Normalization on Housing Features\n",
    "\n",
    "- **The formula compresses every feature into [0, 1] without distorting relative spacing.** Because Min-Max divides by the range (max ‚àí min), a value at the minimum maps to 0, one at the maximum maps to 1, and everything in between keeps its proportional position. The sanity check confirms all five normalized columns have min = 0.0 and max = 1.0 exactly as expected.\n",
    "\n",
    "- **Raw scale differences of multiple orders of magnitude vanish after normalization.** Before normalization, `Price` spans ~\\$977,000 while `Num_Bedrooms` spans only 4 ‚Äî a ratio of ~245,000:1. A distance-based algorithm like KNN would effectively ignore bedroom count entirely. After normalization both features span [0, 1] and contribute equally to distance calculations, which is precisely the goal.\n",
    "\n",
    "- **Min-Max is sensitive to outliers, so the training-set min/max must be stored and reused.** The normalization anchors to the *observed* min and max in the dataset. If a future house is priced above the training maximum (> \\$1,077,909), its normalized price will exceed 1.0, violating the [0, 1] guarantee. This means we must save the training-set min/max values and apply them at inference time ‚Äî never recompute them on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d75072",
   "metadata": {},
   "source": [
    "\n",
    "## üß© Challenge Extension: After Normalization, Which Features Matter Most?\n",
    "\n",
    "You've normalized the housing features so they share a common scale.  \n",
    "Now comes a common next step in ML workflows:\n",
    "\n",
    "> **How do we identify the most important directions (principal components) in the data‚Äîand how might these relate to a target variable like `Price`?**\n",
    "\n",
    "This introduces **Principal Component Analysis (PCA)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö PCA Theory (Conceptual)\n",
    "\n",
    "### What PCA *is*\n",
    "PCA is an **unsupervised** dimensionality reduction technique that:\n",
    "- Finds **new axes** (principal components) that are **linear combinations** of your original features.\n",
    "- Orders these axes so that:\n",
    "  - **PC1** captures the **most variance** in the feature space,\n",
    "  - **PC2** captures the next most variance, and so on,\n",
    "  - Each PC is **orthogonal** (uncorrelated) with the previous ones.\n",
    "\n",
    "### What PCA is *not*\n",
    "PCA does **not** directly find features that \"impact the target variable\" because it does not use the target in its optimization.\n",
    "\n",
    "However, you *can*:\n",
    "- Compute PCs from the feature matrix **X** (after normalization),\n",
    "- Then measure how PCs relate to the target **y** (e.g., correlation with `Price`, or a simple regression on PCs),\n",
    "- Interpret which original features contribute most to PCs that are most related to **y**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† The Math (high level)\n",
    "Given a centered feature matrix \\(X\\) (often standardized/normalized first):\n",
    "\n",
    "1. Compute covariance matrix:\n",
    "$$\n",
    "\\Sigma = \\frac{1}{n-1}X^\\top X\n",
    "$$\n",
    "\n",
    "2. Find eigenvectors (principal directions) and eigenvalues (variance captured):\n",
    "$$\n",
    "\\Sigma v_i = \\lambda_i v_i\n",
    "$$\n",
    "\n",
    "- $ v_i $ are **principal component directions** (loadings)\n",
    "- $ \\lambda_i $ are the **variance explained** by each component\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Normalize Before PCA?\n",
    "PCA is sensitive to scale. Without normalization/standardization:\n",
    "- A large-scale feature (e.g., `Price`) can dominate variance\n",
    "- PCs will reflect units rather than structure\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Student Challenge\n",
    "Using the **housing dataset**:\n",
    "\n",
    "1. Apply PCA to the normalized feature matrix \\(X\\) (exclude ID columns and the target).\n",
    "2. Determine how many components are needed to explain **‚â• 90%** of the variance.\n",
    "3. Identify which original features contribute most to:\n",
    "   - **PC1** and **PC2**, and\n",
    "   - the **PC most correlated with the target** (`Price`).\n",
    "4. Write a short interpretation:\n",
    "   - \"What does PC1 represent in housing terms?\"\n",
    "   - \"Do the PCs that explain the most variance also relate most strongly to `Price`?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ec558",
   "metadata": {},
   "source": [
    "\n",
    "### üîó How to Integrate This With Your Step 1 Normalization\n",
    "\n",
    "- If you created normalized columns (e.g., `Area_sqft_norm`), use those in `candidate_features`.\n",
    "- If you normalized in-place (overwriting original columns), you can use the original names.\n",
    "- PCA should **not** include:\n",
    "  - `House_ID` (identifier)\n",
    "  - non-numeric categorical columns (unless encoded appropriately)\n",
    "- Decide intentionally whether to include `Year_Built`:\n",
    "  - It's numeric, but it may behave differently than size/price-related features.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Deliverable for the Challenge\n",
    "Add a Markdown cell answering:\n",
    "\n",
    "1. How many PCs explain at least **90%** variance?\n",
    "2. Which features contribute most to **PC1** and **PC2**?\n",
    "3. Which PC is most correlated with `Price`?\n",
    "4. In plain language: what do you think PC1 represents?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0959376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Variance Explained by Each PC ===\n",
      "  PC1: 0.4953  (cumulative: 0.4953)\n",
      "  PC2: 0.3600  (cumulative: 0.8554)\n",
      "  PC3: 0.0803  (cumulative: 0.9356)\n",
      "  PC4: 0.0644  (cumulative: 1.0000)\n",
      "\n",
      "‚û°Ô∏è  3 components needed to explain >= 90% of variance\n",
      "\n",
      "=== PC Loadings (feature weights per component) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PC1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PC2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PC3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PC4",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b7a3018a-ceba-46b8-b41c-32ca19ddf9ea",
       "rows": [
        [
         "Area_sqft_norm",
         "0.0015",
         "0.0174",
         "-0.1236",
         "0.9922"
        ],
        [
         "Num_Bedrooms_norm",
         "0.0534",
         "0.9983",
         "0.0203",
         "-0.0151"
        ],
        [
         "Num_Bathrooms_norm",
         "0.9986",
         "-0.0533",
         "-0.0052",
         "-0.0013"
        ],
        [
         "Lot_Size_norm",
         "0.0043",
         "-0.0185",
         "0.9921",
         "0.1239"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Area_sqft_norm</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>-0.1236</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bedrooms_norm</th>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>-0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Bathrooms_norm</th>\n",
       "      <td>0.9986</td>\n",
       "      <td>-0.0533</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>-0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lot_Size_norm</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>-0.0185</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.1239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PC1     PC2     PC3     PC4\n",
       "Area_sqft_norm      0.0015  0.0174 -0.1236  0.9922\n",
       "Num_Bedrooms_norm   0.0534  0.9983  0.0203 -0.0151\n",
       "Num_Bathrooms_norm  0.9986 -0.0533 -0.0052 -0.0013\n",
       "Lot_Size_norm       0.0043 -0.0185  0.9921  0.1239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dominant feature per PC:\n",
      "  PC1: Num_Bathrooms_norm  (loading = 0.9986)\n",
      "  PC2: Num_Bedrooms_norm  (loading = 0.9983)\n",
      "  PC3: Lot_Size_norm  (loading = 0.9921)\n",
      "  PC4: Area_sqft_norm  (loading = 0.9922)\n",
      "\n",
      "=== Pearson Correlation of Each PC with Price_norm ===\n",
      "  PC1: r = -0.0114\n",
      "  PC2: r = -0.0054\n",
      "  PC3: r = 0.0172\n",
      "  PC4: r = -0.0152\n",
      "\n",
      "‚û°Ô∏è  PC3 is most correlated with Price (r = 0.0172)\n"
     ]
    }
   ],
   "source": [
    "# --- PCA on the normalized feature matrix ---\n",
    "# Uses the normalized columns produced in Step 1 (df_norm).\n",
    "# Price_norm is the target ‚Äî excluded from X, used for correlation in Step F.\n",
    "# Year_Built is excluded: it is a year label, not a magnitude/size feature.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ---- Step A: Choose target and feature columns ----\n",
    "target = df_norm['Price_norm']\n",
    "candidate_features = ['Area_sqft_norm', 'Num_Bedrooms_norm', 'Num_Bathrooms_norm', 'Lot_Size_norm']\n",
    "X = df_norm[candidate_features].values\n",
    "\n",
    "# ---- Step B: Center the data (mean = 0 per feature) ----\n",
    "# sklearn PCA centers automatically, but we do it explicitly to show the step.\n",
    "X_centered = X - X.mean(axis=0)\n",
    "\n",
    "# ---- Step C: Fit PCA ----\n",
    "pca = PCA()          # keep all components for full inspection\n",
    "pca.fit(X_centered)\n",
    "\n",
    "# ---- Step D: Variance explained ----\n",
    "evr = pca.explained_variance_ratio_\n",
    "cumulative_evr = np.cumsum(evr)\n",
    "\n",
    "print('=== Variance Explained by Each PC ===')\n",
    "for i, (v, cv) in enumerate(zip(evr, cumulative_evr), 1):\n",
    "    print(f'  PC{i}: {v:.4f}  (cumulative: {cv:.4f})')\n",
    "\n",
    "n_components_90 = int(np.argmax(cumulative_evr >= 0.90)) + 1\n",
    "print(f'\\n‚û°Ô∏è  {n_components_90} components needed to explain >= 90% of variance')\n",
    "\n",
    "# ---- Step E: Loadings (feature contributions to each PC) ----\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=candidate_features,\n",
    "    columns=[f'PC{i}' for i in range(1, len(candidate_features) + 1)]\n",
    ")\n",
    "print('\\n=== PC Loadings (feature weights per component) ===')\n",
    "display(loadings.round(4))\n",
    "\n",
    "print('\\nDominant feature per PC:')\n",
    "for pc in loadings.columns:\n",
    "    dominant = loadings[pc].abs().idxmax()\n",
    "    print(f'  {pc}: {dominant}  (loading = {loadings.loc[dominant, pc]:.4f})')\n",
    "\n",
    "# ---- Step F: Relate PCs to the target (Pearson correlation) ----\n",
    "pc_scores = pca.transform(X_centered)\n",
    "print('\\n=== Pearson Correlation of Each PC with Price_norm ===')\n",
    "correlations = {}\n",
    "for i in range(len(candidate_features)):\n",
    "    r = np.corrcoef(pc_scores[:, i], target.values)[0, 1]\n",
    "    correlations[f'PC{i+1}'] = r\n",
    "    print(f'  PC{i+1}: r = {r:.4f}')\n",
    "\n",
    "best_pc = max(correlations, key=lambda k: abs(correlations[k]))\n",
    "print(f'\\n‚û°Ô∏è  {best_pc} is most correlated with Price (r = {correlations[best_pc]:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã PCA Challenge ‚Äî Answers\n",
    "\n",
    "| Question | Answer |\n",
    "|----------|--------|\n",
    "| How many PCs explain ‚â• 90% variance? | **3 PCs** ‚Äî PC1 = 49.5%, PC1+PC2 = 85.5%, PC1+PC2+PC3 = 93.6% |\n",
    "| Dominant feature in PC1? | **Num_Bathrooms_norm** (loading ‚âà +0.999) |\n",
    "| Dominant feature in PC2? | **Num_Bedrooms_norm** (loading ‚âà +0.998) |\n",
    "| PC most correlated with Price? | **PC3** (r ‚âà 0.017) ‚Äî but all PCs correlate near-zero with Price |\n",
    "| What does PC1 represent? | PC1 is almost entirely the bathroom-count axis. Bathroom count varies nearly independently of the other three features, so it alone captures ~50% of the total variance in the feature matrix. |\n",
    "| Do high-variance PCs predict Price? | **No.** PC1 and PC2 together explain ~86% of feature-space variance yet correlate near-zero with Price (\\|r\\| < 0.02). PCA is unsupervised ‚Äî it maximises spread in X, not predictive power over y. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Talking Points #2 ‚Äî PCA on Normalized Housing Features\n",
    "\n",
    "- **Three principal components are sufficient to capture ‚â• 90% of the variance, and each PC maps cleanly to one original feature.** PC1 (49.5%) is dominated by `Num_Bathrooms_norm`, PC2 (36.0%) by `Num_Bedrooms_norm`, and PC3 (8.0%) by `Lot_Size_norm`. The fact that each component loads almost entirely on a single feature tells us these four housing attributes are nearly uncorrelated ‚Äî there is very little shared variance to compress, so PCA doesn't produce much dimensionality reduction here.\n",
    "\n",
    "- **High variance explained by a PC does not imply that PC predicts the target.** All four PCs have near-zero Pearson correlation with `Price_norm` (|r| < 0.02). The PC explaining the most feature-space variance (PC1 at ~50%) has essentially no linear relationship with house price. This is a textbook illustration of why PCA is called *unsupervised*: it finds directions of maximum spread in the feature matrix, which are not necessarily the directions most useful for predicting a label.\n",
    "\n",
    "- **The normalization done in Step 1 was a prerequisite for valid PCA results.** Without it, `Price` (range ~\\$977k) would have dominated the covariance matrix by a factor of ~245,000 over `Num_Bedrooms` (range 4), and PC1 would simply have been the price axis ‚Äî telling us nothing about the structure of the other features. Scaling all features to [0, 1] first ensures PCA responds to actual covariance patterns rather than differences in measurement units."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
